import marimo

__generated_with = "0.17.2"
app = marimo.App(width="medium")


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    # Load pretrained instances with an AutoClass

    æœ¬ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã§ã¯ã€`AutoClass` ã‚’ç”¨ã„ã¦ã€ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ç›®çš„ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹æ‰‹æ³•ã‚’å­¦ã³ã¾ã™ã€‚
    `pipeline()` ãŒäº‹å‰å‡¦ç†ãƒ»æ¨è«–ãƒ»äº‹å¾Œå‡¦ç†ã‚’ä¸€æŒ™ã«è¡Œã†ãƒ¢ãƒ‡ãƒ«å…¨ä½“ã‚’æä¾›ã—ã¦ã„ãŸã®ã¨ã¯å¯¾ç…§çš„ã«ã€`AutoClass` ã‚’ç”¨ã„ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹æˆã™ã‚‹å„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’é¸æŠçš„ã«ãƒ­ãƒ¼ãƒ‰ã—ã€åˆ©ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

    æœ¬ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã¯ã€[Hugging Face Tranformers ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«](https://huggingface.co/docs/transformers/v4.57.0/ja/autoclass_tutorial) ã‚’å…ƒã«ã€ä¸€éƒ¨åŠ ç­†ãƒ»ä¿®æ­£ã—ã¦ä½œæˆã—ã¦ã„ã¾ã™ã€‚
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## Dependencies

    ã“ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã‚³ãƒ¼ãƒ‰ã‚’ã™ã¹ã¦å®Ÿè¡Œã™ã‚‹ãŸã‚ã«ã¯ã€æ˜ç¤ºçš„ã« `import` ã™ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ä»–ã«ã€ä»¥ä¸‹ã®ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ãŒå¿…è¦ã§ã™ã€‚

    - [`tesseract`](https://github.com/tesseract-ocr/tesseract) (ãŠã‚ˆã³ã€ãã® Python ãƒ©ãƒƒãƒ‘ãƒ¼: `pytesseract`): ç”»åƒå‡¦ç† (ocr)
    - `torch` ãƒ©ã‚¤ãƒ–ãƒ©ãƒª or `tensorflow` ãƒ©ã‚¤ãƒ–ãƒ©ãƒª: ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰
        - æœ¬ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã§ã¯ `torch` ã‚’ç”¨ã„ã‚‹ã‚³ãƒ¼ãƒ‰ã—ã‹ç´¹ä»‹ã—ã¾ã›ã‚“
    """
    )
    return


@app.cell
def _():
    # run this cell if you are working in google colab

    # %pip install pytesseract
    return


@app.cell
def _():
    import io
    import librosa
    from PIL import Image
    import requests
    from transformers import (
        AutoConfig,
        AutoFeatureExtractor,
        AutoImageProcessor,
        AutoModel,
        AutoModelForSequenceClassification,
        AutoModelForTokenClassification,
        AutoTokenizer,
        AutoProcessor,
    )
    return (
        AutoConfig,
        AutoFeatureExtractor,
        AutoImageProcessor,
        AutoModel,
        AutoModelForSequenceClassification,
        AutoModelForTokenClassification,
        AutoProcessor,
        AutoTokenizer,
        Image,
        io,
        librosa,
        requests,
    )


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## `ğŸ¤— Tranformers` architecture

    ä¸€èˆ¬çš„ã«ã€`ğŸ¤— Transformers` ãŒæä¾›ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã¯ã€æ¬¡ã®ã‚ˆã†ãªéƒ¨å“ã‹ã‚‰æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚

    - processor: ãƒˆãƒ¼ã‚«ãƒŠã‚¤ã‚¶ãªã©ã®ã€äº‹å‰ãƒ»äº‹å¾Œå‡¦ç†ã‚’è¡Œã†ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
    - model: ãƒ¢ãƒ‡ãƒ«æœ¬ä½“
    - head: model ã®å‡ºåŠ›ã‚’ã‚¿ã‚¹ã‚¯å›ºæœ‰ã®å‡ºåŠ›ã«å¤‰æ›ã™ã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

    `pipeline()` ã§ã¯ã“ã‚Œã‚‰ã‚’ã¾ã¨ã‚ã¦ãƒ­ãƒ¼ãƒ‰ã—ã¦ã„ã¾ã—ãŸãŒã€`AutoClass` ã¯ã“ã‚Œã‚‰ã‚’ã‚ˆã‚Šç´°ã‹ã„å˜ä½ã§ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ä»•çµ„ã¿ãŒç”¨æ„ã•ã‚Œã¦ã„ã¾ã™ã€‚
    """
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## AutoConfig

    model ã«é–¢ã™ã‚‹æƒ…å ±ã¯ã€`config.json` ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚
    ã“ã‚Œã‚‰ã®æƒ…å ±ã‚’å¼•ãå‡ºã™ãŸã‚ã«ã€`AutoConfig` ã‚¯ãƒ©ã‚¹ã‚’ç”¨ã„ã¾ã™ã€‚
    `AutoConfig.from_pretrained("model")` ã¨ã™ã‚‹ã“ã¨ã§ã€ä¸Šè¿°ã® `config.json` ãŒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã€ãã®å†…å®¹ãŒæ ¼ç´ã•ã‚ŒãŸ `xxxConfig` ã‚¯ãƒ©ã‚¹ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãŒä½œæˆã•ã‚Œã¾ã™ã€‚
    """
    )
    return


@app.cell
def _(AutoConfig):
    # model: "openai/gpt2" (0.1B params)
    # ref: https://huggingface.co/openai-community/gpt2

    config = AutoConfig.from_pretrained("openai-community/gpt2")
    print(config)
    return (config,)


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## AutoTokenizer

    **ãƒˆãƒ¼ã‚«ãƒŠã‚¤ã‚¶**ã¯ã€å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã«å¯¾ã—ã¦ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ãƒ»ãƒ†ãƒ³ã‚½ãƒ«åŒ–ãªã©ã®å¤‰æ›ã‚’è¡Œã†ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã™ã€‚
    ãƒˆãƒ¼ã‚«ãƒŠã‚¤ã‚¶ã«é–¢ã™ã‚‹æƒ…å ±ã¯ã€ãƒˆãƒ¼ã‚«ãƒŠã‚¤ã‚¶ã‚’åˆ©ç”¨ã™ã‚‹ã‚ˆã†ãªè¨€èªå‡¦ç†ãƒ¢ãƒ‡ãƒ«ã®æ§‹æˆãƒ•ã‚¡ã‚¤ãƒ«ã®ã†ã¡ã€`tokenizer_config.json` ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ (ä»¥ä¸‹ã§ç´¹ä»‹ã™ã‚‹äº‹å‰å‡¦ç†ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã¤ã„ã¦ã‚‚ã€å¯¾å¿œã™ã‚‹ config ãƒ•ã‚¡ã‚¤ãƒ«ãŒãƒ¢ãƒ‡ãƒ«ã‚’æ§‹æˆã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ç¾¤ã«å«ã¾ã‚Œã¦ã„ã¾ã™) ã€‚

    ãƒˆãƒ¼ã‚«ãƒŠã‚¤ã‚¶ã®ãƒ­ãƒ¼ãƒ‰ã«ã¯ã€`AutoTokenizer` ã‚¯ãƒ©ã‚¹ã‚’ç”¨ã„ã¾ã™ã€‚
    `AutoTokenizer` ã‚’ã¯ã˜ã‚ã¨ã™ã‚‹ processor ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ç”¨ã®ã‚¯ãƒ©ã‚¹ã«ã¯ã€`from_pretrained` ãƒ¡ã‚½ãƒƒãƒ‰ãŒç”¨æ„ã•ã‚Œã¦ã„ã¾ã™ã€‚
    `AutoTokenizer.from_pretrained("model name")` ã«ã‚ˆã‚Šã€ä¸Šè¿°ã® config ãƒ•ã‚¡ã‚¤ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã€`xxxTokenizer` ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãŒä½œæˆã•ã‚Œã¾ã™ã€‚
    """
    )
    return


@app.cell
def _(AutoTokenizer):
    # model: "google-bert/bert-base-uncased" (110M params)
    # ref: https://huggingface.co/google-bert/bert-base-uncased

    tokenizer = AutoTokenizer.from_pretrained("google-bert/bert-base-uncased")
    print(tokenizer)

    sequence = "In a hole in the ground there lived a hobbit."
    print(tokenizer(sequence))
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## AutoImageProcessor

    ç”»åƒãƒ—ãƒ­ã‚»ãƒƒã‚µã¯ã€å…¥åŠ›ç”»åƒã«ã‚µã‚¤ã‚ºå¤‰æ›´ãƒ»æ­£è¦åŒ–ãƒ»ãƒ†ãƒ³ã‚½ãƒ«åŒ–ãªã©ã®å¤‰æ›ã‚’è¡Œã†ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã™ã€‚
    ã“ã“ã§ã¯ `AutoImageProcessor` ã‚¯ãƒ©ã‚¹ã‚’ç”¨ã„ã¾ã™ã€‚
    """
    )
    return


@app.cell
def _(AutoImageProcessor, Image, io, requests):
    # model: "google/vit-base-patch16-224" (86.6M params)
    # ref: https://huggingface.co/google/vit-base-patch16-224

    image_processor = AutoImageProcessor.from_pretrained("google/vit-base-patch16-224")
    print(image_processor)

    image1_url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg"
    image1 = Image.open(io.BytesIO(requests.get(image1_url).content))
    print(image_processor(image1))
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## AutoFeatureExtractor

    ç‰¹å¾´æŠ½å‡ºå™¨ã¯ã€å…¥åŠ›ã®ç”»åƒã‚„å‹•ç”»ã«å¯¾ã—ã¦ã€ä¸€å®šã®æ–¹æ³•ã§ç‰¹å¾´ã‚’æŠ½å‡ºã—ã€æ­£è¦åŒ–ãƒ»ãƒ†ãƒ³ã‚½ãƒ«åŒ–ãªã©ã®å¤‰æ›ã‚’è¡Œã†ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã™ã€‚
    ã“ã“ã§ã¯ã€`AutoFeatureExtractor` ã‚¯ãƒ©ã‚¹ã‚’ç”¨ã„ã¾ã™ã€‚

    <audio src="https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac" controls></audio>
    """
    )
    return


@app.cell
def _(AutoFeatureExtractor, io, librosa, requests):
    # model: "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition" (316M params)
    # ref: https://huggingface.co/ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition

    feature_extractor = AutoFeatureExtractor.from_pretrained(
        "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
    )
    print(feature_extractor)

    target_sr = feature_extractor.sampling_rate
    speech_url = "https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac"
    speech_bytes = io.BytesIO(requests.get(speech_url).content)
    speech, sr = librosa.load(speech_bytes, sr=None)
    if sr != target_sr:
        speech = librosa.resample(speech, orig_sr=sr, target_sr=target_sr)
        sr = target_sr

    print(feature_extractor(speech))
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## AutoProcessor

    `Transformers` ã«ãŠã„ã¦ã€ãƒ—ãƒ­ã‚»ãƒƒã‚µã¨ã¯ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã®å…¥åŠ›ã«å¯¾ã—ã¦å‰å‡¦ç†ã‚’è¡Œã†ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æŒ‡ã—ã¾ã™ã€‚
    ã“ã“ã§ã¯ã€`AutoProcessor` ã‚¯ãƒ©ã‚¹ã‚’ç”¨ã„ã¾ã™ã€‚

    <img src="https://huggingface.co/spaces/impira/docquery/resolve/2359223c1837a7587402bda0f2643382a6eefeab/invoice.png" width="30%">
    """
    )
    return


@app.cell
def _(AutoProcessor, Image, io, requests):
    # model: "microsoft/layoutlmv2-base-uncased" (200M params)
    # ref: https://huggingface.co/microsoft/layoutlmv2-base-uncased

    processor = AutoProcessor.from_pretrained("microsoft/layoutlmv2-base-uncased")
    print(processor)

    image2_url = "https://huggingface.co/spaces/impira/docquery/resolve/2359223c1837a7587402bda0f2643382a6eefeab/invoice.png"
    image2 = Image.open(io.BytesIO(requests.get(image2_url).content)).convert("RGB")
    text = ["invoice", "number"]
    print(processor(images=[image2, image2], text=text, return_tensors="pt", padding=True))
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## AutoModel

    model ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãŸã‚ã«ã¯ã€`AutoModel` ã‚¯ãƒ©ã‚¹ã‚’ç”¨ã„ã¾ã™ã€‚
    `AutoModel` ã‚¯ãƒ©ã‚¹ã«ã¯ã€`from_config` ã¨ `from_pretrained` ã®2ç¨®é¡ã®ãƒ¡ã‚½ãƒƒãƒ‰ãŒç”¨æ„ã•ã‚Œã¦ã„ã¾ã™ã€‚

    `from_config` ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã€`xxxConfig` ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ã‚‚ã¨ã«ã€`xxxModel` ã‚’çµ„ã¿ç«‹ã¦ã¾ã™ã€‚
    ã“ã®æ–¹æ³•ã§ã¯ã€model ã‚’æ§‹æˆã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ãƒ©ãƒ³ãƒ€ãƒ ã«åˆæœŸåŒ–ã•ã‚Œã¾ã™ã€‚

    `from_pretrained` ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã€ãƒ¢ãƒ‡ãƒ«åã‚’å—ã‘å–ã‚Šã€äº‹å‰å­¦ç¿’æ¸ˆã¿ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€`xxxModel` ã‚’çµ„ã¿ç«‹ã¦ã¾ã™ã€‚
    äº‹å‰å­¦ç¿’æ¸ˆã¿ model ã‚’åˆ©ç”¨ã—ã¦ã€æ¨è«–ã‚„ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã†ã«ã¯ã€ã“ã¡ã‚‰ã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚
    """
    )
    return


@app.cell
def _(AutoModel, config):
    # config = AutoConfig.from_pretrained("openai-community/gpt2")

    AutoModel.from_config(config)
    return


@app.cell
def _(AutoModel):
    AutoModel.from_pretrained("openai-community/gpt2")
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## AutoModelFor

    model ã¨åŒæ™‚ã« head ã‚‚ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãŸã‚ã«ã¯ã€`AutoModelFor` ã‚¯ãƒ©ã‚¹ (`PyTorch` ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰) ã¾ãŸã¯ `TFAutoModelFor` ã‚¯ãƒ©ã‚¹ (`tensorflow` ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰) ã‚’ç”¨ã„ã¾ã™ã€‚
    ã“ã“ã§ã‚‚ã€`AutoModel` ã¨åŒæ§˜ã«ã€`from_config` ãƒ¡ã‚½ãƒƒãƒ‰ã¨ `from_pretrained` ãƒ¡ã‚½ãƒƒãƒ‰ãŒç”¨æ„ã•ã‚Œã¦ã„ã¾ã™ã€‚
    """
    )
    return


@app.cell
def _(AutoModelForSequenceClassification):
    # model: "distilbert/distilbert-base-uncased" (67M params)
    # ref: https://huggingface.co/distilbert/distilbert-base-uncased

    AutoModelForSequenceClassification.from_pretrained("distilbert/distilbert-base-uncased")
    return


@app.cell
def _(AutoModelForTokenClassification):
    AutoModelForTokenClassification.from_pretrained("distilbert/distilbert-base-uncased")
    return


@app.cell
def _():
    import marimo as mo
    return (mo,)


if __name__ == "__main__":
    app.run()
