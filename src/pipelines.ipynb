{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dd7420c",
   "metadata": {},
   "source": [
    "# Pipelines for inferenece\n",
    "\n",
    "æœ¬ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã§ã¯ã€`pieline()` ã‚’ç”¨ã„ã¦ã€è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦æ§˜ã€…ãªæ¨è«–ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹æ‰‹æ³•ã‚’å­¦ã³ã¾ã™ã€‚\\\n",
    "ãªãŠã€ã“ã“ã§ç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹å¤šãã®ãƒ¢ãƒ‡ãƒ«ã¯éå¸¸ã«æ²¢å±±ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã‚‚ã¤ãŸã‚ã€ãƒ­ãƒ¼ãƒ‰ã®ãŸã‚ã«å¤šãã®ãƒ¡ãƒ¢ãƒªã‚„ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚’å¿…è¦ã¨ã—ã¾ã™ã€‚\\\n",
    "ãƒ­ãƒ¼ã‚«ãƒ«ã§å®Ÿè¡Œã™ã‚‹éš›ã¯æ³¨æ„ã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "æœ¬ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã¯ã€[Hugging Face Transformers ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«](https://huggingface.co/docs/transformers/v4.57.0/ja/pipeline_tutorial) ã‚’å…ƒã«ã€ä¸€éƒ¨åŠ ç­†ãƒ»ä¿®æ­£ã—ã¦ä½œæˆã—ã¦ã„ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cec0910",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "ã“ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã‚³ãƒ¼ãƒ‰ã‚’ã™ã¹ã¦å®Ÿè¡Œã™ã‚‹ãŸã‚ã«ã¯ã€æ˜ç¤ºçš„ã« `import` ã™ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ä»–ã«ã€ä»¥ä¸‹ã®ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ãŒå¿…è¦ã§ã™ã€‚\n",
    "\n",
    "- [`ffmpeg`](https://www.ffmpeg.org/) (ãŠã‚ˆã³ã€ãã® Python ãƒ©ãƒƒãƒ‘ãƒ¼: `ffmpeg-python`): å‹•ç”»å‡¦ç†\n",
    "- [`tesseract`](https://github.com/tesseract-ocr/tesseract) (ãŠã‚ˆã³ã€ãã® Python ãƒ©ãƒƒãƒ‘ãƒ¼: `pytesseract`): ç”»åƒå‡¦ç†\n",
    "- `accelerate` ãƒ©ã‚¤ãƒ–ãƒ©ãƒª: ãƒ¢ãƒ‡ãƒ«ã®è‡ªå‹•é…ç½®\n",
    "- `bitsandbytes` ãƒ©ã‚¤ãƒ–ãƒ©ãƒª: ãƒ¢ãƒ‡ãƒ«ã®é‡å­åŒ–\n",
    "    - linux, windows ã®ã¿ã‚µãƒãƒ¼ãƒˆ\n",
    "- `pillow` ãƒ©ã‚¤ãƒ–ãƒ©ãƒª: ç”»åƒå‡¦ç†\n",
    "- `torchcodec` ãƒ©ã‚¤ãƒ–ãƒ©ãƒª: å‹•ç”»å‡¦ç†\n",
    "\n",
    "ã‚‚ã—è‡ªåˆ†ã®ç’°å¢ƒã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„å ´åˆã«ã¯ã€äº‹å‰ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãŠã„ã¦ãã ã•ã„ã€‚\\\n",
    "ãªãŠã€`ffmpeg` ã¨ `tesseract` ã«é–¢ã—ã¦ã¯ã€macOSã§ã‚ã‚Œã° [`Homebrew`](https://formulae.brew.sh) ã‹ã‚‰ç°¡å˜ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ãã‚‹ã‚ˆã†ã§ã™ (å‹•ä½œæœªç¢ºèª) ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07ef203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell if you are working in google colab\n",
    "\n",
    "!pip install accelerate bitsandbytes datasets ffmpeg-python transformers torch torchcodec pillow pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d859a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from transformers.pipelines.pt_utils import KeyDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b093c6e",
   "metadata": {},
   "source": [
    "## Pipeline usage\n",
    "\n",
    "`pipeline(task=\"task\")` ã«ã‚ˆã‚Šã€æ¨è«–ã‚¿ã‚¹ã‚¯ `\"task\"` ã‚’è¡Œã†ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ¢ãƒ‡ãƒ«ãŒæä¾›ã•ã‚Œã¾ã™ã€‚\\\n",
    "æä¾›ã•ã‚Œã‚‹æ§‹é€ ä½“ã¯ã€äº‹å‰å‡¦ç†ãƒ»æ¨è«–ãƒ»äº‹å¾Œå‡¦ç†ã‚’ãƒ¯ãƒ³ãƒ©ã‚¤ãƒŠãƒ¼ã§è¡Œã„ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aa2859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare generator with task name\n",
    "# default model: \"facebook/wav2vec2-base-960h\" (94.4M params)\n",
    "# ref: (https://huggingface.co/facebook/wav2vec2-base-960h)\n",
    "\n",
    "generator = pipeline(task=\"automatic-speech-recognition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39734103",
   "metadata": {},
   "source": [
    "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šã—ã¦ã€æ¨è«–ã‚’è¡Œã„ã¾ã™ã€‚\n",
    "\n",
    "<audio src=\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\" controls></audio>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909f87f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate with input text\n",
    "# target: \"I have a dream that one day this nation will rise up and live out the true meaning of its creed ...\" (Martin Luther King Jr.)\n",
    "\n",
    "generator(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3cc773",
   "metadata": {},
   "source": [
    "å…·ä½“çš„ãªãƒ¢ãƒ‡ãƒ«ã‚’æŒ‡å®šã™ã‚‹ã«ã¯ã€`pipeline(model=\"model\")` ã¨ã—ã¾ã™ã€‚\\\n",
    "ãƒ¢ãƒ‡ãƒ«ã®ä¸€è¦§ã¯ [`Hub`](https://huggingface.co/models) ã‹ã‚‰ç¢ºèªã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9592c228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare generator with model name\n",
    "# superior model: \"openai/whisper-large\" (1.54B params, heavy)\n",
    "\n",
    "generator = pipeline(model=\"openai/whisper-large\")\n",
    "generator(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94391fa",
   "metadata": {},
   "source": [
    "è¤‡æ•°ã®å…¥åŠ›ã‚’ `list` ã§å—ã‘å–ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚\n",
    "\n",
    "<audio src=\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\" controls></audio>\n",
    "<audio src=\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/1.flac\" controls></audio>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ac6e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target 1: \"I have a dream that one day this nation will rise up and live out the true meaning of its creed ...\" (Martin Luther King Jr.)\n",
    "# target 2: \"He hoped there would be stew for dinner, turnips and carrots and bruised potatoes and fat mutton pieces to be ladled out in thick peppered flour-fattened sauce.\" (James Joyce, \"A Portrait Of The Artist As A Young Man\")\n",
    "\n",
    "generator(\n",
    "    [\n",
    "        \"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\",\n",
    "        \"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/1.flac\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d70644",
   "metadata": {},
   "source": [
    "## Parameter\n",
    "`pipeline()` ã¯ã‚¿ã‚¹ã‚¯å›ºæœ‰ãƒ»éå›ºæœ‰ã®å¤šãã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚\\\n",
    "ä¸€èˆ¬çš„ã«ã¯ã€ã“ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ã©ã“ã§ã‚‚æŒ‡å®šã§ãã¾ã™ã€‚\n",
    "\n",
    "```python\n",
    "generator = pipeline(model=\"openai/whisper-large\", my_parameter=1)\n",
    "out = generator(...)                  # `my_parameter=1` is used here\n",
    "out = generator(..., my_parameter=2)  # `my_parameter=2` is used here (overwritten)\n",
    "out = generator(...)                  # `my_parameter=1` is used again here\n",
    "```\n",
    "\n",
    "ä»¥ä¸‹ã§ã€ç‰¹ã«é‡è¦ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2c5e97",
   "metadata": {},
   "source": [
    "### Device\n",
    "\n",
    "`device=n` ã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€ãƒ¢ãƒ‡ãƒ«ãŒæŒ‡å®šã—ãŸãƒ‡ãƒã‚¤ã‚¹ã«è‡ªå‹•çš„ã«é…ç½®ã•ã‚Œã¾ã™ã€‚\\\n",
    "å…·ä½“çš„ãª use case ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚\n",
    "\n",
    "- `device=-1`: CPU\n",
    "- `device=n` (non-negative integer): id `n` ã«å¯¾å¿œã™ã‚‹ GPU\n",
    "    - id ã¯ãƒã‚·ãƒ³ä¸Šã®å„ GPU ã«è‡ªå‹•çš„ã«å‰²ã‚ŠæŒ¯ã‚‰ã‚Œã¦ã„ã¾ã™\n",
    "    - NVIDIA GPU ã§ã‚ã‚Œã° `torch.cuda.get_device_name(n)` ã§ id `n` ã«å¯¾å¿œã™ã‚‹ GPU ã®åå‰ãŒå–å¾—ã§ãã¾ã™\n",
    "\n",
    "ãªãŠã€ç‰¹ã«æŒ‡å®šã—ãªã„å ´åˆã«ã¯ã€GPU ã‚’ä½¿ç”¨ã™ã‚‹ã‚ˆã†ã«è‡ªå‹•çš„ã«ãƒ‡ãƒã‚¤ã‚¹ãŒæ±ºå®šã•ã‚Œã‚‹ã‚ˆã†ã§ã™ã€‚\\\n",
    "ç­†è€…ã®ç’°å¢ƒ (Macbook Air M4) ã§ã¯ã€Apple GPU (`mps`) ãŒè‡ªå‹•çš„ã«è¨­å®šã•ã‚Œã¾ã—ãŸã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b15d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run \"openai/whisper-large\" on GPU[0]\n",
    "\n",
    "generator = pipeline(model=\"openai/whisper-large\", device=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98feebf2",
   "metadata": {},
   "source": [
    "ã‚‚ã—ãƒ¢ãƒ‡ãƒ«ãŒå˜ä¸€ã®GPUã«ã¯å¤§ãã™ãã‚‹å ´åˆã€`device_map=\"auto\"` ã‚’æŒ‡å®šã—ã¦ã€`ğŸ¤— Accelerate` ã«ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’ã©ã®ã‚ˆã†ã«ãƒ­ãƒ¼ãƒ‰ã—ã€ä¿å­˜ã™ã‚‹ã‹ã‚’è‡ªå‹•çš„ã«æ±ºå®šã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae1a893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run \"openai/whisper-large\" on GPU (loaded)\n",
    "\n",
    "generator = pipeline(model=\"openai/whisper-large\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd03e539",
   "metadata": {},
   "source": [
    "### Batch Size\n",
    "\n",
    "`batch_size=n` ã‚’æŒ‡å®šã™ã‚‹ã“ã¨ã§ã€ãƒãƒƒãƒã‚µã‚¤ã‚º `n` ã§æ¨è«–ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\\\n",
    "ãŸã ã—ã€ãƒãƒƒãƒå‡¦ç†ã¯å¿…ãšã—ã‚‚é€Ÿã„ã‚ã‘ã§ã¯ãªãã€å®Ÿéš›ã«ã„ãã¤ã‹ã®ã‚±ãƒ¼ã‚¹ã§ã‹ãªã‚Šé…ããªã‚‹ã“ã¨ãŒç¢ºèªã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã§ã™ã€‚\\\n",
    "ãªãŠã€ãƒãƒƒãƒå‡¦ç†ã‚’è¡Œã£ãŸã¨ã—ã¦ã‚‚ã€å¾—ã‚‰ã‚Œã‚‹çµæœã¯ãƒãƒƒãƒå‡¦ç†ã‚’è¡Œã‚ãªã„å ´åˆã¨ä¸€è‡´ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95edb362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batched inference\n",
    "\n",
    "generator = pipeline(model=\"openai/whisper-large\", device=0, batch_size=2)\n",
    "audio_filenames = [f\"audio_{i}.flac\" for i in range(10)]\n",
    "texts = generator(audio_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663de307",
   "metadata": {},
   "source": [
    "### Task specific parameters\n",
    "\n",
    "ã™ã¹ã¦ã®ã‚¿ã‚¹ã‚¯ã¯ã‚¿ã‚¹ã‚¯å›ºæœ‰ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚\\\n",
    "ãŸã¨ãˆã°ã€`transformers.AutomaticSpeechRecognitionPipeline.call()` ãƒ¡ã‚½ãƒƒãƒ‰ã«ã¯ã€ãƒ“ãƒ‡ã‚ªã®å­—å¹•ä½œæˆã«æœ‰ç”¨ãª `return_timestamps` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb60259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# speech recognition with time stamp\n",
    "# model: \"facebook/wav2vec2-large-960h-lv60-self\" (317M params)\n",
    "# ref: https://huggingface.co/facebook/wav2vec2-large-960h-lv60-self\n",
    "\n",
    "generator = pipeline(model=\"facebook/wav2vec2-large-960h-lv60-self\", return_timestamps=\"word\")\n",
    "generator(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89a8713",
   "metadata": {},
   "source": [
    "## Using pipeline in a dataset\n",
    "\n",
    "`pipeline()` ã¯å¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸Šã§æ¨è«–ã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚\\\n",
    "ä¾‹ãˆã°ã€ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦ã€ã“ã‚Œã‚’ç°¡å˜ã«å®Ÿè¡Œã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82163ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# speech recognition with time stamp\n",
    "# model: \"openai-community/gpt2\" (137M params)\n",
    "# ref: https://huggingface.co/openai-community/gpt2\n",
    "\n",
    "def data():\n",
    "    for i in range(1000):\n",
    "        yield f\"My example {i}\"\n",
    "\n",
    "pipe = pipeline(model=\"openai-community/gpt2\", device=0)\n",
    "generated_characters = 0\n",
    "for out in pipe(data()):\n",
    "    generated_characters += len(out[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8ae8df",
   "metadata": {},
   "source": [
    "`ğŸ¤— Datasets` ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦ç¹°ã‚Šè¿”ã—åå¾©ã•ã›ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ff03a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KeyDataset is a util that will just output the item we're interested in.\n",
    "\n",
    "pipe = pipeline(model=\"hf-internal-testing/tiny-random-wav2vec2\", device=0)\n",
    "dataset = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation[:10]\")\n",
    "\n",
    "for out in pipe(KeyDataset(dataset, \"audio\")):\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88370ab",
   "metadata": {},
   "source": [
    "## Using pipelines for a webserver\n",
    "\n",
    "skip this section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf6d9e4",
   "metadata": {},
   "source": [
    "## Vision pipeline\n",
    "\n",
    "ç”»åƒå‡¦ç†ã‚¿ã‚¹ã‚¯ã« `pipeline()` ã‚’ç”¨ã„ã‚‹æ–¹æ³•ã‚‚ã»ã¼åŒã˜ã§ã™ã€‚\\\n",
    "ã“ã“ã§ã¯ã€å†™çœŸä¸Šã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’åˆ†é¡ã™ã‚‹æ¨è«–ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™ã€‚\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\" width=\"30%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a0e1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: \"google/vit-base-patch16-224\" (86.6M params)\n",
    "# ref: https://huggingface.co/google/vit-base-patch16-224\n",
    "\n",
    "vision_classifier = pipeline(model=\"google/vit-base-patch16-224\")\n",
    "preds = vision_classifier(\n",
    "    inputs=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\",\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42865868",
   "metadata": {},
   "source": [
    "## Text pipeline\n",
    "\n",
    "ä¸Šã¨åŒæ§˜ã§ã™ã€‚\\\n",
    "ã“ã“ã§ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’åˆ†é¡ã™ã‚‹æ¨è«–ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a7efec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: \"facebook/bart-large-mnli\" (407M params)\n",
    "# ref: https://huggingface.co/facebook/bart-large-mnli\n",
    "\n",
    "classifier = pipeline(model=\"facebook/bart-large-mnli\")\n",
    "classifier(\n",
    "    \"I have a problem with my iphone that needs to be resolved asap!!\",\n",
    "    candidate_labels=[\"urgent\", \"not urgent\", \"phone\", \"tablet\", \"computer\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5510654f",
   "metadata": {},
   "source": [
    "## Multimodal pipeline\n",
    "\n",
    "`pipeline()` ã¯ã€è¤‡æ•°ã®ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚\\\n",
    "ãŸã¨ãˆã°ã€ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã¨ç”»åƒå‡¦ç†ã‚’çµ„ã¿åˆã‚ã›ã¦ã€ç”»åƒã«ã¤ã„ã¦ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã®æ¨è«–ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n",
    "\n",
    "<img src=\"https://huggingface.co/spaces/impira/docquery/resolve/2359223c1837a7587402bda0f2643382a6eefeab/invoice.png\" width=\"30%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b12a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: \"impira/layoutlm-document-qa\" (128M params)\n",
    "# ref: https://huggingface.co/impira/layoutlm-document-qa\n",
    "\n",
    "vqa = pipeline(model=\"impira/layoutlm-document-qa\")\n",
    "output = vqa(\n",
    "    image=\"https://huggingface.co/spaces/impira/docquery/resolve/2359223c1837a7587402bda0f2643382a6eefeab/invoice.png\",\n",
    "    question=\"What is the invoice number?\",\n",
    ")\n",
    "output[0][\"score\"] = round(output[0][\"score\"], 3)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b907e3db",
   "metadata": {},
   "source": [
    "## Using pipeline on large models with ğŸ¤— accelerate\n",
    "\n",
    "`device_map=\"auto\"` ã‚’æŒ‡å®šã—ã¦ã€å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨å¯èƒ½ãªãƒ‡ãƒã‚¤ã‚¹ã«é©åˆ‡ã«åˆ†é…ã—ã¦ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32efaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: \"facebook/opt-1.3b\" (1.3B params, heavy)\n",
    "# ref: https://huggingface.co/facebook/opt-1.3b\n",
    "\n",
    "pipe = pipeline(model=\"facebook/opt-1.3b\", dtype=torch.bfloat16, device_map=\"auto\")\n",
    "pipe(\"ã“ã‚Œã¯ç´ æ™´ã‚‰ã—ã„ä¾‹ã§ã™ï¼\", do_sample=True, top_p=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97031ae3",
   "metadata": {},
   "source": [
    "ã•ã‚‰ã«ã€`bitsandbytes` ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã€`load_in_8bit=True` ã‚’æŒ‡å®šã™ã‚Œã°ã€ãƒ¢ãƒ‡ãƒ«ã‚’ 8 bit ã§èª­ã¿è¾¼ã‚€ã“ã¨ãŒã§ãã¾ã™ã€‚\\\n",
    "ãªãŠã€`bitsandbytes` ã¯ç¾çŠ¶ linux ã¨ windows ã—ã‹ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã›ã‚“ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63735f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipe = pipeline(model=\"facebook/opt-1.3b\", device_map=\"auto\", model_kwargs={\"load_in_8bit\": True})\n",
    "pipe(\"This is a cool example!\", do_sample=True, top_p=0.95)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
