{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88ae4248",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Load pretrained instances with an AutoClass\n",
    "\n",
    "本チュートリアルでは、`AutoClass.from_pretrained()` を用いて、訓練済みモデルから目的のアーキテクチャをロードする方法を学びます。\\\n",
    "`pipeline()` が事前処理・推論・事後処理を一挙に行うモデル全体を提供していたのとは対照的に、`AutoClass.from_pretrained()` はモデルを構成する各アーキテクチャを選択的にロードし、別のタスクのために利用することができます。\n",
    "\n",
    "本チュートリアルは、[Hugging Face Tranformers チュートリアル](https://huggingface.co/docs/transformers/v4.57.0/ja/autoclass_tutorial) を元に、一部加筆・修正して作成しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb81424",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "このチュートリアルコードをすべて実行するためには、明示的に `import` するライブラリの他に、以下のソフトウェアが必要です。\n",
    "\n",
    "- `pytesseract` ライブラリ: 動画処理\n",
    "- `torch` ライブラリ (or `tensorflow` ライブラリ): `AutoModelForSequenceClassification` クラスなどのバックエンド\n",
    "    - 本チュートリアルでは `torch` を用いるコードしか紹介しません\n",
    "\n",
    "もし自分の環境にインストールされていない場合には、事前にインストールしておいてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e89e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell if you are working in google colab\n",
    "\n",
    "!pip install librosa pytesseract pillow torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f78e9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import librosa\n",
    "from PIL import Image\n",
    "import requests\n",
    "from transformers import (\n",
    "    AutoFeatureExtractor,\n",
    "    AutoImageProcessor,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoTokenizer,\n",
    "    AutoProcessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b8429f",
   "metadata": {},
   "source": [
    "## AutoTokenizer\n",
    "\n",
    "Tokenizer は、入力テキストにトークン化・テンソル化などの変換を行うアーキテクチャです。\\\n",
    "ここでは `AutoTokenizer` クラスを用います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ba9749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: \"google-bert/bert-base-uncased\" (110M params)\n",
    "# ref: https://huggingface.co/google-bert/bert-base-uncased\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "sequence = \"In a hole in the ground there lived a hobbit.\"\n",
    "print(tokenizer(sequence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86325e1c",
   "metadata": {},
   "source": [
    "## AutoImageProcessor\n",
    "\n",
    "画像プロセッサは、入力画像にサイズ変更・正規化・テンソル化などの変更を行うアーキテクチャです。\\\n",
    "ここでは `AutoImageProcessor` クラスを用います。\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\" width=\"30%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d4fe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: \"google/vit-base-patch16-224\" (86.6M params)\n",
    "# ref: https://huggingface.co/google/vit-base-patch16-224\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "image_url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
    "image = Image.open(io.BytesIO(requests.get(image_url).content))\n",
    "print(image_processor(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c9bf36",
   "metadata": {},
   "source": [
    "## AutoFeatureExtractor\n",
    "\n",
    "特徴抽出器は、入力の画像や動画から一定の方法で特徴を抽出し、正規化・テンソル化などの変換を行うアーキテクチャです。\\\n",
    "ここでは、`AutoFeatureExtractor` クラスを用います。\n",
    "\n",
    "<audio src=\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\" controls></audio>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b977c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: \"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\" (316M params)\n",
    "# ref: https://huggingface.co/ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\n",
    "    \"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\",\n",
    ")\n",
    "target_sr = feature_extractor.sampling_rate\n",
    "speech_url = \"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\"\n",
    "speech_bytes = io.BytesIO(requests.get(speech_url).content)\n",
    "speech, sr = librosa.load(speech_bytes, sr=None)\n",
    "if sr != target_sr:\n",
    "    speech = librosa.resample(speech, orig_sr=sr, target_sr=target_sr)\n",
    "    sr = target_sr\n",
    "print(feature_extractor(speech))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd224850",
   "metadata": {},
   "source": [
    "## AutoProcessor\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2040c995",
   "metadata": {},
   "source": [
    "`Transformers` において、プロセッサはマルチモーダルモデルの入力に対して前処理を行うアーキテクチャを指します。\\\n",
    "ここでは、`AutoProcessor` クラスを用います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ab90bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: \"microsoft/layoutlmv2-base-uncased\" (200M params)\n",
    "# ref: https://huggingface.co/microsoft/layoutlmv2-base-uncased\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"microsoft/layoutlmv2-base-uncased\")\n",
    "image_url = \"https://huggingface.co/spaces/impira/docquery/resolve/2359223c1837a7587402bda0f2643382a6eefeab/invoice.png\"\n",
    "image = Image.open(io.BytesIO(requests.get(image_url).content)).convert(\"RGB\")\n",
    "text = [\"invoice\", \"number\"]\n",
    "print(processor(images=[image, image], text=text, return_tensors=\"pt\", padding=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4c3ba9",
   "metadata": {},
   "source": [
    "## AutoModel\n",
    "\n",
    "特定のタスクに対して訓練済みモデルを `torch.Tensor` (`tf.Tensor`) 形式でロードするためには、`AutoModelFor` クラス (`TFAutoModelFor` クラス) を用います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bc2245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: \"distilbert/distilbert-base-uncased\" (67M params)\n",
    "# ref: https://huggingface.co/distilbert/distilbert-base-uncased\n",
    "\n",
    "AutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932571dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "AutoModelForTokenClassification.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
