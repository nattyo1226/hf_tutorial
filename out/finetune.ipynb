{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "Hbol",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "# Fine-tune a pretrained model\n",
    "\n",
    "本チュートリアルでは、事前学習済みモデルに対してファインチューニングを行う方法を学びます。\n",
    "事前学習済みモデルに対して、特定のタスクに合わせたデータセットで追加の学習を行得ことで、ドメイン特化のモデルを得ることが期待できます。\n",
    "\n",
    "本チュートリアルは、[Hugging Face Tranformers チュートリアル](https://huggingface.co/docs/transformers/v4.57.1/ja/training) を元に、一部加筆・修正して作成しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MJUe",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Dependencies\n",
    "\n",
    "このチュートリアルコードをすべて実行するためには、明示的に `import` するライブラリの他に必要なものは特にありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vblA",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell if you are working in google colab\n",
    "\n",
    "%pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bkHC",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    get_scheduler,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lEQa",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Prepare a dataset\n",
    "\n",
    "今回は、[google-bert/bert-base-cased](https://huggingface.co/google-bert/bert-base-cased) (BERT) という Masked Language Model (MLM) をファインチューンしてみます。\n",
    "MLM とは、文章中の隠された (masked) 部分に当てはまる単語を推測するタスクを行う言語モデルです。\n",
    "BERT は [BookCorpus](https://yknzhu.wixsite.com/mbweb) と呼ばれる、11308 冊の未出版書籍と、英語の Wikipedia によって事前学習が行われています。\n",
    "\n",
    "今回は、BERT に対して、[yelp_review_full](https://huggingface.co/datasets/Yelp/yelp_review_full) というデータセットでファインチューニングを行います。\n",
    "このデータセットは、飲食店や店舗のレビューサイトである Yelp 上のレビュー文章から構成されています。\n",
    "早速、データセットをロードしましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PKri",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"yelp_review_full\")\n",
    "dataset[\"train\"][100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Xref",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "データセットがロードできたら、トーカナイザをロードして事前処理を行いましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SFPL",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BYtC",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "実行時間短縮のために、データセットから適当な部分セットを作成できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RGSE",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Kclp",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Train\n",
    "\n",
    "追加データセットの準備ができたので、ここから本格的にファインチューニングを行っていきます。\n",
    "ファインチューニングを行う手法にはいくつかあり、代表的なものは以下の 3 通りです。\n",
    "\n",
    "- `🤗 Transformers` が提供する `Trainer` クラスを利用するもの\n",
    "- `Kelas` API を利用して `TensorFlow` で訓練するもの\n",
    "- ネイティブの `PyTorch` で訓練するもの\n",
    "\n",
    "これらの利点・欠点は下表のとおりです。\n",
    "\n",
    "| method | advantage 👍 | disadvantage 👎 |\n",
    "|: ---- |: ---- |: ---- |\n",
    "| `Trainer` | 高水準 API を用いて短いコードで実装できる | カスタム性に欠ける |\n",
    "| `Kelas` + `TensorFlow` | `TensorFlow` 専用の TPU ハードウェアや `Keras` の API が利用できる | `🤗 Transformers` はそもそも `PyTorch` 中心で、一部の機能は PyTorch 限定 |\n",
    "| Native `PyTorch` | 低水準 API を用いて柔軟にカスタマイズできる | コード量が多く、実装が比較的複雑 |\n",
    "\n",
    "本チュートリアルでは、`Trainer` と Native `PyTorch` の 2 通りの手法を紹介します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emfo",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "### Train with PyTorch Trainer\n",
    "\n",
    "`Trainer` クラスを用いたファインチューニングの手順を紹介します。\n",
    "`🤗 Transformers` が提供する高水準 API を用いて、数行のプログラムで簡潔に記述することができます。\n",
    "\n",
    "まずモデルをロードし、予想される (マスクされる) ラベルの数を指定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hstk",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-cased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nWHF",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "#### Training Hyperparameters\n",
    "\n",
    "学習時のオプションとハイパーパラメータから構成される `TrainingArguments` クラスを作成します。\n",
    "学習時のオプションとは、例えば学習後のパラメータファイルの保存先や、損失関数の値のログのタイミングなどを含みます。\n",
    "また、ハイパーパラメータとは、学習率のスケジューラやエポック数などを含みます。\n",
    "何も指定しなければ、デフォルトの値が利用されます。\n",
    "\n",
    "```python\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iLit",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "#### Evaluate\n",
    "\n",
    "`Trainer` は、デフォルトではモデルのパフォーマンスを評価しません。\n",
    "モデルのパフォーマンス評価を行うには、メトリクスを計算して報告する関数を `Trainer` に渡す必要があります。\n",
    "`🤗 Evaluate` ライブラリでは、`evaluate.load` 関数を使用して読み込むことができる、`accuracy` 関数が用意されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZHCJ",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ROlb",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "`metric.compute()` を呼ぶことで、予測精度を計算することができます。\n",
    "なお、すべての `🤗 Transformers` モデルの出力は logit だそうです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qnkX",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TqIu",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "評価メトリクスをファインチューニング中に計算したい場合、学習引数 `eval_strategy` を利用できます。\n",
    "今回は、各エポック終了時に計算するように設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Vxnm",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir=\"test_trainer\", eval_strategy=\"epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DnEU",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "#### Trainer\n",
    "\n",
    "モデル、学習引数、トレーニング/テストデータセット、評価メトリクスを指定して、`Trainer` オブジェクトを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ulZA",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfG",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "`Trainer.train()` を実行して、ファインチューニングが行われます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Pvdt",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZBYS",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "### Train in native Pytorch\n",
    "\n",
    "次に、ネイティブ `PyTorch` でファイチューニングを行う手順を紹介します。\n",
    "複雑ではあるものの、カスタマイズ性の高い学習ループを構成できます。\n",
    "なお、以下の部分は上で定義した変数と衝突するため、`marimo` でチュートリアルを実行している方は、一度セッションを切って、`Trainer` API による実装部分をコメントアウトしてから、以下のプログラムを実行してください。\n",
    "\n",
    "まずデータセットのロードを行うのですが、\n",
    "\n",
    "1. モデルはトークン化前のオリジナルテキストを受け取らないので、`text` 列を削除する。\n",
    "2. モデルは引数の名前を `labels` と期待しているので、`label` 列を `labels` に名前を変更しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aLJB",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell if you are working on ipynb (google colab)\n",
    "\n",
    "# del model\n",
    "# del trainer\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nHfw",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_datasets_in_need = tokenized_datasets.remove_columns([\"text\"])\n",
    "# tokenized_datasets_pt = tokenized_datasets_in_need.rename_column(\"label\", \"labels\")\n",
    "# tokenized_datasets_pt.set_format(\"torch\")\n",
    "\n",
    "# small_train_dataset_pt = tokenized_datasets_pt[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "# small_eval_dataset_pt = tokenized_datasets_pt[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xXTn",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "#### DataLoader\n",
    "\n",
    "トレーニングデータセットとテストデータセット用の `DataLoader` を作成して、データのバッチをイテレータとして取り出せるようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AjVT",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataloader = DataLoader(small_train_dataset_pt, shuffle=True, batch_size=8)\n",
    "# eval_dataloader = DataLoader(small_eval_dataset_pt, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pHFh",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "併せて、モデルのロードも行ってしまいます。\n",
    "やり方は `Trainer` の場合と同じです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NCOB",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-cased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aqbW",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "#### Opeimizer and learning rate scheduler\n",
    "\n",
    "オプティマイザと学習率スケジューラを作成します。\n",
    "ここでは、`AdamW` を用いてモデルの最適化を行うことにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TRpd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TXez",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epochs = 3\n",
    "# num_training_steps = num_epochs * len(train_dataloader)\n",
    "# lr_scheduler = get_scheduler(\n",
    "#     name=\"linear\",\n",
    "#     optimizer=optimizer,\n",
    "#     num_warmup_steps=0,\n",
    "#     num_training_steps=num_training_steps,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dNNg",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "また、ファインチューニングを行うデバイスを指定しておきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yCnT",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for NVIDIA GPU (CUDA)\n",
    "# device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# for Apple GPU (MPS)\n",
    "# device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wlCL",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "#### Train\n",
    "\n",
    "学習の進捗を追跡するために、`tqdm` ライブラリを使用して進行状況バーを表示させます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kqZH",
   "metadata": {},
   "outputs": [],
   "source": [
    "# progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "# model.train()\n",
    "# for epoch in range(num_epochs):\n",
    "#     for batch_t in train_dataloader:\n",
    "#         batch_train = {k: v.to(device) for k, v in batch_t.items()}\n",
    "#         outputs_train = model(**batch_train)\n",
    "#         loss = outputs.loss\n",
    "#         loss.backward()\n",
    "\n",
    "#         optimizer.step()\n",
    "#         lr_scheduler.step()\n",
    "#         optimizer.zero_grad()\n",
    "#         progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wAgl",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "#### Evaluate\n",
    "\n",
    "`Trainer` の際と同様に、評価メトリックを導入します。\n",
    "ここでは、各エポックの最後にメトリックを計算する代わりに、`add_batch` を使用してすべてのバッチを蓄積しておき、最後にメトリックを計算することにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rEll",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric = evaluate.load(\"accuracy\")\n",
    "# model.eval()\n",
    "# for batch_e in eval_dataloader:\n",
    "#     batch_eval = {k: v.to(device) for k, v in batch_e.items()}\n",
    "#     with torch.no_grad():\n",
    "#         outputs_eval = model(**batch_eval)\n",
    "\n",
    "#     logits = outputs_eval.logits\n",
    "#     predictions = torch.argmax(logits, dim=-1)\n",
    "#     metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "# metric.compute()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
