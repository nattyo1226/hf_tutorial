{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "Hbol",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "# Load pretrained instances with an AutoClass\n",
    "\n",
    "本チュートリアルでは、`AutoClass.from_pretrained()` メソッドを用いて、訓練済みモデルから目的のアーキテクチャをロードする手法を学びます。\n",
    "`pipeline()` が事前処理・推論・事後処理を一挙に行うモデル全体を提供していたのとは対照的に、`AutoClass.from_pretrained()` はモデルを構成する各アーキテクチャを選択的にロードし、別のタスクのために利用することができます。\n",
    "\n",
    "本チュートリアルは、[Hugging Face Tranformers チュートリアル](https://huggingface.co/docs/transformers/v4.57.0/ja/autoclass_tutorial) を元に、一部加筆・修正して作成しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MJUe",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Dependencies\n",
    "\n",
    "このチュートリアルコードをすべて実行するためには、明示的に `import` するライブラリの他に、以下のソフトウェアが必要です。\n",
    "\n",
    "- [`tesseract`](https://github.com/tesseract-ocr/tesseract) (および、その Python ラッパー: `pytesseract`): 動画処理\n",
    "- `torch` ライブラリ or `tensorflow` ライブラリ: `AutoModelForSequenceClassification` クラスなどのバックエンド\n",
    "    - 本チュートリアルでは `torch` を用いるコードしか紹介しません"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vblA",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell if you are working in google colab\n",
    "\n",
    "# %pip install libsora pytesseract pillow torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bkHC",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import librosa\n",
    "from PIL import Image\n",
    "import requests\n",
    "from transformers import (\n",
    "    AutoFeatureExtractor,\n",
    "    AutoImageProcessor,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoTokenizer,\n",
    "    AutoProcessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lEQa",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## AutoTokenizer\n",
    "\n",
    "Tokinizer は、入力テキストに対してトークン化・テンソル化などの変換を行うアーキテクチャです。\n",
    "ここでは、`AutoTokenizer` クラスを用います。\n",
    "\n",
    "以下のサンプルコードではいくつか出力が表示されますが、その意味については事前処理についてのチュートリアルに譲り、ここでは詳しい説明を省きます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PKri",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: \"google-bert/bert-base-uncased\" (110M params)\n",
    "# ref: https://huggingface.co/google-bert/bert-base-uncased\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "sequence = \"In a hole in the ground there lived a hobbit.\"\n",
    "\n",
    "tokenizer(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SFPL",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: \"google/vit-base-patch16-224\" (86.6M params)\n",
    "# ref: https://huggingface.co/google/vit-base-patch16-224\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "image1_url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
    "image1 = Image.open(io.BytesIO(requests.get(image1_url).content))\n",
    "\n",
    "image_processor(image1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BYtC",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## AutoFeatureExtractor\n",
    "\n",
    "特徴抽出器は、入力の画像や動画に対して、一定の方法で特徴を抽出し、正規化・テンソル化などの変換を行うアーキテクチャです。\n",
    "ここでは、`AutoFeatureExtractor` クラスを用います。\n",
    "\n",
    "<audio src=\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\" controls></audio>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RGSE",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: \"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\" (316M params)\n",
    "# ref: https://huggingface.co/ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\n",
    "    \"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\",\n",
    ")\n",
    "target_sr = feature_extractor.sampling_rate\n",
    "speech_url = \"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\"\n",
    "speech_bytes = io.BytesIO(requests.get(speech_url).content)\n",
    "speech, sr = librosa.load(speech_bytes, sr=None)\n",
    "if sr != target_sr:\n",
    "    speech = librosa.resample(speech, orig_sr=sr, target_sr=target_sr)\n",
    "    sr = target_sr\n",
    "\n",
    "feature_extractor(speech)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Xref",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## AutoImageProcessor\n",
    "\n",
    "画像プロセッサは、入力画像にサイズ変更・正規化・テンソル化などの変換を行うアーキテクチャです。\n",
    "ここでは `AutoImageProcessor` クラスを用います。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Kclp",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## AutoProcessor\n",
    "\n",
    "`Transformers` において、プロセッサとはマルチモーダルモデルの入力に対して前処理を行うアーキテクチャを指します。\n",
    "ここでは、`AutoProcessor` クラスを用います。\n",
    "\n",
    "<img src=\"https://huggingface.co/spaces/impira/docquery/resolve/2359223c1837a7587402bda0f2643382a6eefeab/invoice.png\" width=\"30%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emfo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: \"microsoft/layoutlmv2-base-uncased\" (200M params)\n",
    "# ref: https://huggingface.co/microsoft/layoutlmv2-base-uncased\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"microsoft/layoutlmv2-base-uncased\")\n",
    "image2_url = \"https://huggingface.co/spaces/impira/docquery/resolve/2359223c1837a7587402bda0f2643382a6eefeab/invoice.png\"\n",
    "image2 = Image.open(io.BytesIO(requests.get(image2_url).content)).convert(\"RGB\")\n",
    "text = [\"invoice\", \"number\"]\n",
    "\n",
    "processor(images=[image2, image2], text=text, return_tensors=\"pt\", padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Hstk",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## AutoModel\n",
    "\n",
    "特定のタスクに対して訓練済みモデルを `torch.Tensor` (`tf.Tensor`) 形式でロードするためには、`AutoModelFor` クラス (`TFAutoModelFor` クラス) を用います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nWHF",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: \"distilbert/distilbert-base-uncased\" (67M params)\n",
    "# ref: https://huggingface.co/distilbert/distilbert-base-uncased\n",
    "\n",
    "AutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iLit",
   "metadata": {},
   "outputs": [],
   "source": [
    "AutoModelForTokenClassification.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
