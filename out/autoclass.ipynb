{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "Hbol",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "# Load pretrained instances with an AutoClass\n",
    "\n",
    "本チュートリアルでは、`AutoClass` を用いて、モデルから目的のアーキテクチャをロードする手法を学びます。\n",
    "`pipeline()` が事前処理・推論・事後処理を一挙に行うモデル全体を提供していたのとは対照的に、`AutoClass` を用いることで、モデルを構成する各アーキテクチャを選択的にロードし、利用することができます。\n",
    "\n",
    "本チュートリアルは、[Hugging Face Tranformers チュートリアル](https://huggingface.co/docs/transformers/v4.57.0/ja/autoclass_tutorial) を元に、一部加筆・修正して作成しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MJUe",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Dependencies\n",
    "\n",
    "このチュートリアルコードをすべて実行するためには、明示的に `import` するライブラリの他に、以下のソフトウェアが必要です。\n",
    "\n",
    "- [`tesseract`](https://github.com/tesseract-ocr/tesseract) (および、その Python ラッパー: `pytesseract`):画像処理 (ocr)\n",
    "- `torch` ライブラリ or `tensorflow` ライブラリ: バックエンド\n",
    "    - 本チュートリアルでは `torch` を用いるコードしか紹介しません"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vblA",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell if you are working in google colab\n",
    "\n",
    "%pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bkHC",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import librosa\n",
    "from PIL import Image\n",
    "import requests\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoFeatureExtractor,\n",
    "    AutoImageProcessor,\n",
    "    AutoModel,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoTokenizer,\n",
    "    AutoProcessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lEQa",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## `🤗 Tranformers` architecture\n",
    "\n",
    "一般的に、`🤗 Transformers` が提供するモデルは、次のような部品から構成されています。\n",
    "\n",
    "- processor: トーカナイザなどの、事前・事後処理を行うアーキテクチャ\n",
    "- model: モデル本体\n",
    "- head: model の出力をタスク固有の出力に変換するアーキテクチャ\n",
    "\n",
    "`pipeline()` ではこれらをまとめてロードしていましたが、`AutoClass` はこれらをより細かい単位でロードする仕組みが用意されています。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PKri",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## AutoConfig\n",
    "\n",
    "model に関する情報は、`config.json` に保存されています。\n",
    "これらの情報を引き出すために、`AutoConfig` クラスを用います。\n",
    "`AutoConfig.from_pretrained(\"model\")` とすることで、上述の `config.json` がダウンロードされ、その内容が格納された `xxxConfig` クラスのインスタンスが作成されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xref",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: \"openai/gpt2\" (0.1B params)\n",
    "# ref: https://huggingface.co/openai-community/gpt2\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"openai-community/gpt2\")\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SFPL",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## AutoTokenizer\n",
    "\n",
    "**トーカナイザ**は、入力テキストに対してトークン化・テンソル化などの変換を行うアーキテクチャです。\n",
    "トーカナイザに関する情報は、トーカナイザを利用するような言語処理モデルの構成ファイルのうち、`tokenizer_config.json` に保存されています (以下で紹介する事前処理アーキテクチャについても、対応する config ファイルがモデルを構成するファイル群に含まれています) 。\n",
    "\n",
    "トーカナイザのロードには、`AutoTokenizer` クラスを用います。\n",
    "`AutoTokenizer` をはじめとする processor アーキテクチャ用のクラスには、`from_pretrained` メソッドが用意されています。\n",
    "`AutoTokenizer.from_pretrained(\"model name\")` により、上述の config ファイルが読み込まれ、`xxxTokenizer` インスタンスが作成されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BYtC",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: \"google-bert/bert-base-uncased\" (110M params)\n",
    "# ref: https://huggingface.co/google-bert/bert-base-uncased\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "print(tokenizer)\n",
    "\n",
    "sequence = \"In a hole in the ground there lived a hobbit.\"\n",
    "print(tokenizer(sequence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RGSE",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## AutoImageProcessor\n",
    "\n",
    "画像プロセッサは、入力画像にサイズ変更・正規化・テンソル化などの変換を行うアーキテクチャです。\n",
    "ここでは `AutoImageProcessor` クラスを用います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kclp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: \"google/vit-base-patch16-224\" (86.6M params)\n",
    "# ref: https://huggingface.co/google/vit-base-patch16-224\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "print(image_processor)\n",
    "\n",
    "image1_url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
    "image1 = Image.open(io.BytesIO(requests.get(image1_url).content))\n",
    "print(image_processor(image1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emfo",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## AutoFeatureExtractor\n",
    "\n",
    "特徴抽出器は、入力の画像や動画に対して、一定の方法で特徴を抽出し、正規化・テンソル化などの変換を行うアーキテクチャです。\n",
    "ここでは、`AutoFeatureExtractor` クラスを用います。\n",
    "\n",
    "<audio src=\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\" controls></audio>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hstk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: \"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\" (316M params)\n",
    "# ref: https://huggingface.co/ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\n",
    "    \"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\",\n",
    ")\n",
    "print(feature_extractor)\n",
    "\n",
    "target_sr = feature_extractor.sampling_rate\n",
    "speech_url = \"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\"\n",
    "speech_bytes = io.BytesIO(requests.get(speech_url).content)\n",
    "speech, sr = librosa.load(speech_bytes, sr=None)\n",
    "if sr != target_sr:\n",
    "    speech = librosa.resample(speech, orig_sr=sr, target_sr=target_sr)\n",
    "    sr = target_sr\n",
    "\n",
    "print(feature_extractor(speech))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nWHF",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## AutoProcessor\n",
    "\n",
    "`Transformers` において、プロセッサとはマルチモーダルモデルの入力に対して前処理を行うアーキテクチャを指します。\n",
    "ここでは、`AutoProcessor` クラスを用います。\n",
    "\n",
    "<img src=\"https://huggingface.co/spaces/impira/docquery/resolve/2359223c1837a7587402bda0f2643382a6eefeab/invoice.png\" width=\"30%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iLit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: \"microsoft/layoutlmv2-base-uncased\" (200M params)\n",
    "# ref: https://huggingface.co/microsoft/layoutlmv2-base-uncased\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"microsoft/layoutlmv2-base-uncased\")\n",
    "print(processor)\n",
    "\n",
    "image2_url = \"https://huggingface.co/spaces/impira/docquery/resolve/2359223c1837a7587402bda0f2643382a6eefeab/invoice.png\"\n",
    "image2 = Image.open(io.BytesIO(requests.get(image2_url).content)).convert(\"RGB\")\n",
    "text = [\"invoice\", \"number\"]\n",
    "print(processor(images=[image2, image2], text=text, return_tensors=\"pt\", padding=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZHCJ",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## AutoModel\n",
    "\n",
    "model をロードするためには、`AutoModel` クラスを用います。\n",
    "`AutoModel` クラスには、`from_config` と `from_pretrained` の2種類のメソッドが用意されています。\n",
    "\n",
    "`from_config` メソッドは、`xxxConfig` インスタンスをもとに、`xxxModel` を組み立てます。\n",
    "この方法では、model を構成するパラメータはランダムに初期化されます。\n",
    "\n",
    "`from_pretrained` メソッドは、モデル名を受け取り、事前学習済みのパラメータをロードして、`xxxModel` を組み立てます。\n",
    "事前学習済み model を利用して、推論やファインチューニングを行うには、こちらを利用することになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ROlb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(\"openai-community/gpt2\")\n",
    "AutoModel.from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qnkX",
   "metadata": {},
   "outputs": [],
   "source": [
    "AutoModel.from_pretrained(\"openai-community/gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TqIu",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## AutoModelFor\n",
    "\n",
    "model と同時に head もロードするためには、`AutoModelFor` クラス (`PyTorch` バックエンド) または `TFAutoModelFor` クラス (`tensorflow` バックエンド) を用います。\n",
    "ここでも、`AutoModel` と同様に、`from_config` メソッドと `from_pretrained` メソッドが用意されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Vxnm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: \"distilbert/distilbert-base-uncased\" (67M params)\n",
    "# ref: https://huggingface.co/distilbert/distilbert-base-uncased\n",
    "\n",
    "AutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DnEU",
   "metadata": {},
   "outputs": [],
   "source": [
    "AutoModelForTokenClassification.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
