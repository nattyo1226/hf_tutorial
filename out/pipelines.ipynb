{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "Hbol",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "# Pipelines for inference\n",
    "\n",
    "æœ¬ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã§ã¯ã€`pipeline()` ã‚’ç”¨ã„ã¦ã€è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦æ§˜ã€…ãªæ¨è«–ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹æ‰‹æ³•ã‚’å­¦ã³ã¾ã™ã€‚\n",
    "ã“ã“ã§ç´¹ä»‹ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®ã†ã¡ã„ãã¤ã‹ã¯éå¸¸ã«å¤šãã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã‚‚ã¤ãŸã‚ã€ãƒ­ãƒ¼ãƒ‰ã®ãŸã‚ã«å¤šãã®ãƒ¡ãƒ¢ãƒªã‚„ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚’å¿…è¦ã¨ã—ã¾ã™ã€‚\n",
    "ãƒ­ãƒ¼ã‚«ãƒ«ã§å®Ÿè¡Œã™ã‚‹éš›ã¯æ³¨æ„ã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "æœ¬ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã¯ã€[Hugging Face Transformers ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«](https://huggingface.co/docs/transformers/v4.57.1/ja/pipeline_tutorial) ã‚’å…ƒã«ã€ä¸€éƒ¨åŠ ç­†ãƒ»ä¿®æ­£ã—ã¦ä½œæˆã—ã¦ã„ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MJUe",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Dependencies\n",
    "\n",
    "ã“ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã‚³ãƒ¼ãƒ‰ã‚’ã™ã¹ã¦å®Ÿè¡Œã™ã‚‹ãŸã‚ã«ã¯ã€æ˜ç¤ºçš„ã« `import` ã™ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ä»–ã«ã€ä»¥ä¸‹ã®ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ãŒå¿…è¦ã§ã™ã€‚\n",
    "\n",
    "- [`ffmpeg`](https://www.ffmpeg.org/): å‹•ç”»å‡¦ç†\n",
    "- [`tesseract`](https://github.com/tesseract-ocr/tesseract) (ãŠã‚ˆã³ã€ãã® Python ãƒ©ãƒƒãƒ‘ãƒ¼: `pytesseract`): ç”»åƒå‡¦ç†\n",
    "- `accelerate` ãƒ©ã‚¤ãƒ–ãƒ©ãƒª: ãƒ¢ãƒ‡ãƒ«ã®è‡ªå‹•é…ç½®\n",
    "- `bitsandbytes` ãƒ©ã‚¤ãƒ–ãƒ©ãƒª: ãƒ¢ãƒ‡ãƒ«ã®é‡å­åŒ–\n",
    "    - linux, windows ã®ã¿ã‚µãƒãƒ¼ãƒˆ\n",
    "- `pillow` ãƒ©ã‚¤ãƒ–ãƒ©ãƒª: ç”»åƒå‡¦ç†\n",
    "- `torchcodec` ãƒ©ã‚¤ãƒ–ãƒ©ãƒª: å‹•ç”»å‡¦ç†\n",
    "\n",
    "ã‚‚ã—è‡ªåˆ†ã®ç’°å¢ƒã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„å ´åˆã«ã¯ã€äº‹å‰ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãŠã„ã¦ãã ã•ã„ã€‚\\\n",
    "ãªãŠã€`ffmpeg` ã¨ `tesseract` ã«é–¢ã—ã¦ã¯ã€macOSã§ã‚ã‚Œã° [`Homebrew`](https://formulae.brew.sh) ã‹ã‚‰ç°¡å˜ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ãã‚‹ã‚ˆã†ã§ã™ (å‹•ä½œæœªç¢ºèª) ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vblA",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell if you are working in google colab\n",
    "\n",
    "%pip install accelerate bitsandbytes datasets transformers torch torchcodec pillow pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bkHC",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "from transformers.pipelines.pt_utils import KeyDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lEQa",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Pipeline usage\n",
    "\n",
    "`pipeline(task=\"task\")` ã«ã‚ˆã‚Šã€æ¨è«–ã‚¿ã‚¹ã‚¯ `\"task\"` ã‚’è¡Œã†ãŸã‚ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ¢ãƒ‡ãƒ«ãŒæä¾›ã•ã‚Œã¾ã™ã€‚\n",
    "æä¾›ã•ã‚Œã‚‹æ§‹é€ ä½“ã¯ã€å…¥åŠ›ã«å¯¾ã—ã¦äº‹å‰å‡¦ç†ãƒ»æ¨è«–ãƒ»äº‹å¾Œå‡¦ç†ã‚’ãƒ¯ãƒ³ãƒ©ã‚¤ãƒŠãƒ¼ã§å®Ÿè¡Œã—ã¾ã™ã€‚\n",
    "\n",
    "<audio src=\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\" controls></audio>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PKri",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default model: \"facebook/wav2vec2-base-960h\" (94.4M params)\n",
    "# ref: (https://huggingface.co/facebook/wav2vec2-base-960h)\n",
    "\n",
    "pipe_asr1 = pipeline(task=\"automatic-speech-recognition\")\n",
    "pipe_asr1(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Xref",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "å…·ä½“çš„ãªæ¨è«–ãƒ¢ãƒ‡ãƒ«ã‚’æŒ‡å®šã™ã‚‹ã«ã¯ã€`pipeline(model=\"model\")` ã¨ã—ã¾ã™ã€‚\n",
    "ãƒ¢ãƒ‡ãƒ«ã®ä¸€è¦§ã¯ [`Hub`](https://huggingface.co/models) ã‹ã‚‰ç¢ºèªã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SFPL",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare generator with model name\n",
    "# superior model: \"openai/whisper-large\" (1.54B params)\n",
    "# this may be too heavy for cpus ...\n",
    "\n",
    "pipe_asr2 = pipeline(model=\"openai/whisper-large\")\n",
    "pipe_asr2(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BYtC",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "è¤‡æ•°ã®å…¥åŠ›ã‚’ `list` ã§å—ã‘å–ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚\n",
    "\n",
    "<audio src=\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\" controls></audio>\n",
    "\n",
    "<audio src=\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/1.flac\" controls></audio>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RGSE",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_asr1([\n",
    "    \"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\",\n",
    "    \"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/1.flac\",\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Kclp",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Parameter\n",
    "\n",
    "`pipeline()` ã¯ã‚¿ã‚¹ã‚¯å›ºæœ‰ãƒ»éå›ºæœ‰ã®å¤šãã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚\n",
    "ä¸€èˆ¬çš„ã«ã¯ã€ã“ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ã©ã“ã§ã‚‚æŒ‡å®šã§ãã¾ã™ã€‚\n",
    "\n",
    "```python\n",
    "pipe = pipeline(..., my_parameter=1)\n",
    "out = pipe(...)                  # `my_parameter=1` is used here\n",
    "out = pipe(..., my_parameter=2)  # `my_parameter=2` is used here\n",
    "out = pipe(...)                  # `my_parameter=1` is used here\n",
    "```\n",
    "\n",
    "ä»¥ä¸‹ã§ã€ç‰¹ã«ã‚ˆãç”¨ã„ã‚‰ã‚Œã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emfo",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "### Device\n",
    "\n",
    "`device=n` ã‚’æŒ‡å®šã™ã‚‹ã¨ã€ãƒ¢ãƒ‡ãƒ«ãŒæŒ‡å®šã—ãŸãƒ‡ãƒã‚¤ã‚¹ã®ãƒ¡ãƒ¢ãƒªã«é…ç½®ã•ã‚Œã¾ã™ã€‚\n",
    "å…·ä½“çš„ãª use case ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚\n",
    "\n",
    "- `device=-1`: CPU\n",
    "- `device=n` (non-negative integer): on GPU with id `n`\n",
    "    - id ã¯ãƒã‚·ãƒ³ã‚’æ§‹æˆã™ã‚‹å„ GPU ã«è‡ªå‹•çš„ã«å‰²ã‚ŠæŒ¯ã‚‰ã‚Œã¦ã„ã¾ã™\n",
    "    - NVIDIA GPU ã§ã‚ã‚Œã° `torch.cuda.get_device_name(n)` ã§ id `n` ã«å¯¾å¿œã™ã‚‹ GPU ãƒ‡ãƒã‚¤ã‚¹åãŒå–å¾—ã§ãã¾ã™\n",
    "\n",
    "ãªãŠã€ç‰¹ã« `device` ã®å€¤ã‚’æŒ‡å®šã—ãªãã¦ã‚‚ã€GPU ã‚’ä½¿ç”¨ã™ã‚‹ã‚ˆã†ã«è‡ªå‹•çš„ã«ãƒ‡ãƒã‚¤ã‚¹ãŒæ±ºå®šã•ã‚Œã‚‹ã‚ˆã†ã§ã™ã€‚\n",
    "ç­†è€…ã®ç’°å¢ƒ (M4 MacBook Air) ã§ã¯ã€Apple GPU (mps) ãŒè‡ªå‹•çš„ã«é¸æŠã•ã‚Œã¾ã—ãŸã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Hstk",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "### Batch Size\n",
    "\n",
    "`batch_size=n` ã‚’æŒ‡å®šã™ã‚‹ã“ã¨ã§ã€ãƒãƒƒãƒã‚µã‚¤ã‚º `n` ã§æ¨è«–ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n",
    "ãŸã ã—ã€ãƒãƒƒãƒå‡¦ç†ã«ã‚ˆã£ã¦å®Ÿè¡Œé€Ÿåº¦ã®å‘ä¸ŠãŒå¿…ãšã—ã‚‚æœŸå¾…ã§ãã‚‹ã‚ã‘ã§ã¯ãªãã€ã„ãã¤ã‹ã®ã‚±ãƒ¼ã‚¹ã§ã¯ã‹ãªã‚Šé…ããªã‚‹ã“ã¨ãŒç¢ºèªã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã§ã™ã€‚\n",
    "ãªãŠã€ãƒãƒƒãƒå‡¦ç†ã‚’è¡Œã£ãŸã¨ã—ã¦ã‚‚ã€å¾—ã‚‰ã‚Œã‚‹çµæœã¯ãƒãƒƒãƒå‡¦ç†ã‚’è¡Œã‚ãªã„å ´åˆã¨ä¸€è‡´ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nWHF",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "### Task specific parameters\n",
    "\n",
    "ã™ã¹ã¦ã®ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€ã‚¿ã‚¹ã‚¯å›ºæœ‰ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒæä¾›ã•ã‚Œã¦ã„ã¾ã™ã€‚\n",
    "ä¾‹ãˆã°ã€`transformers.AutomaticSpeechRecognitionPipeline.call()` ãƒ¡ã‚½ãƒƒãƒ‰ã«ã¯ã€é©å½“ãªå˜ä½ã§æ¨è«–çµæœã‚’åŒºåˆ‡ã£ã¦ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¨åŒæ™‚ã«å‡ºåŠ›ã™ã‚‹ `return_timestamps` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iLit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: \"facebook/wav2vec2-large-960h-lv60-self\" (317M params)\n",
    "# ref: https://huggingface.co/facebook/wav2vec2-large-960h-lv60-self\n",
    "\n",
    "pipe_asr3 = pipeline(model=\"facebook/wav2vec2-large-960h-lv60-self\", return_timestamps=\"word\")\n",
    "pipe_asr3(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZHCJ",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Using pipeline in a dataset\n",
    "\n",
    "`pipeline()` ã¯å¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸Šã§æ¨è«–ã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ROlb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: \"openai-community/gpt2\" (137M params)\n",
    "# ref: https://huggingface.co/openai-community/gpt2\n",
    "\n",
    "def data():\n",
    "    for i in range(10):\n",
    "        yield f\"My example {i}\"\n",
    "\n",
    "pipe_tg1 = pipeline(model=\"openai-community/gpt2\", device=0)\n",
    "generated_characters = 0\n",
    "for out_tg1 in pipe_tg1(data()):\n",
    "    generated_characters += len(out_tg1[0][\"generated_text\"])\n",
    "print(generated_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qnkX",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "`ğŸ¤— Datasets` ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦ç¹°ã‚Šè¿”ã—åå¾©ã•ã›ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TqIu",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_asr4 = pipeline(model=\"hf-internal-testing/tiny-random-wav2vec2\", device=0)\n",
    "dataset_asr1 = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation[:10]\")\n",
    "\n",
    "for out_asr1 in pipe_asr4(KeyDataset(dataset_asr1, \"audio\")):\n",
    "    print(out_asr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Vxnm",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Using pipelines for a webserver\n",
    "\n",
    "ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯é£›ã°ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DnEU",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Vision pipeline\n",
    "\n",
    "ç”»åƒå‡¦ç†ã‚¿ã‚¹ã‚¯ã§ã®ä½¿ç”¨ä¾‹ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚\n",
    "ã“ã“ã§ã¯ã€å†™çœŸã«å†™ã£ã¦ã„ã‚‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’åˆ†é¡ã™ã‚‹æ¨è«–ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™ã€‚\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\" width=\"30%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ulZA",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: \"google/vit-base-patch16-224\" (86.6M params)\n",
    "# ref: https://huggingface.co/google/vit-base-patch16-224\n",
    "\n",
    "pipe_vc1 = pipeline(model=\"google/vit-base-patch16-224\")\n",
    "preds_vc1 = pipe_vc1(\n",
    "    inputs=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\",\n",
    ")\n",
    "preds_vc1 = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds_vc1]\n",
    "preds_vc1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfG",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Text pipeline\n",
    "\n",
    "ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã‚¿ã‚¹ã‚¯ã§ã®ä½¿ç”¨ä¾‹ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚\n",
    "ã“ã“ã§ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®æ€§æ ¼ã‚’åˆ†é¡ã™ã‚‹ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Pvdt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: \"facebook/bart-large-mnli\" (407M params)\n",
    "# ref: https://huggingface.co/facebook/bart-large-mnli\n",
    "\n",
    "pipe_tc1 = pipeline(model=\"facebook/bart-large-mnli\")\n",
    "pipe_tc1(\n",
    "    \"I have a problem with my iphone that needs to be resolved asap!!\",\n",
    "    candidate_labels=[\"urgent\", \"not urgent\", \"phone\", \"tablet\", \"computer\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZBYS",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Multimodal pipeline\n",
    "\n",
    "`pipeline()` ã¯ã€è¤‡æ•°ã®ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚\n",
    "ã“ã“ã§ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã¨ç”»åƒå‡¦ç†ã‚’çµ„ã¿åˆã‚ã›ã¦ã€ç”»åƒã‹ã‚‰ã‚¤ãƒ³ãƒœã‚¤ã‚¹ç•ªå·ã‚’æ¨è«–ã•ã›ã¦ã„ã¾ã™ã€‚\n",
    "\n",
    "<img src=\"https://huggingface.co/spaces/impira/docquery/resolve/2359223c1837a7587402bda0f2643382a6eefeab/invoice.png\" width=\"30%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aLJB",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: \"impira/layoutlm-document-qa\" (128M params)\n",
    "# ref: https://huggingface.co/impira/layoutlm-document-qa\n",
    "\n",
    "pipe_dqa = pipeline(model=\"impira/layoutlm-document-qa\")\n",
    "out_dqa1 = pipe_dqa(\n",
    "    image=\"https://huggingface.co/spaces/impira/docquery/resolve/2359223c1837a7587402bda0f2643382a6eefeab/invoice.png\",\n",
    "    question=\"What is the invoice number?\",\n",
    ")\n",
    "out_dqa1[0][\"score\"] = round(out_dqa1[0][\"score\"], 3)\n",
    "out_dqa1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nHfw",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Using pipeline on large models with ğŸ¤— accelarate\n",
    "\n",
    "`device_map=\"auto\"` ã‚’æŒ‡å®šã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒã‚¤ã‚¹ä¸Šã§é©åˆ‡ã«åˆ†é…ã—ã¦ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚\n",
    "ã“ã‚Œã«ã‚ˆã‚Šã€å˜ä¸€ã®ãƒ‡ãƒã‚¤ã‚¹ã§ã¯ãƒ¡ãƒ¢ãƒªã«ä¹—ã‚Šåˆ‡ã‚‰ãªã„å¤§è¦æ¨¡ãªãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xXTn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: \"facebook/opt-1.3b\" (1.3B params, heavy)\n",
    "# ref: https://huggingface.co/facebook/opt-1.3b\n",
    "\n",
    "# pipe_acc1 = pipeline(model=\"facebook/opt-1.3b\", dtype=torch.bfloat16, device_map=\"auto\")\n",
    "# pipe_acc1(\"ã“ã‚Œã¯ç´ æ™´ã‚‰ã—ã„ä¾‹ã§ã™ï¼\", do_sample=True, top_p=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AjVT",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "ã•ã‚‰ã«ã€`bitsandbytes` ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã®ä¸Šã€`load_in_8bit=True` ã‚’æŒ‡å®šã™ã‚Œã°ã€ãƒ¢ãƒ‡ãƒ«ã‚’ 8 bit ã§é‡å­åŒ–ã—ã¦èª­ã¿è¾¼ã‚€ã“ã¨ãŒã§ãã¾ã™ã€‚\n",
    "ãŸã ã—ã€`bitsandbytes` ã¯ç¾çŠ¶ linux ã¨ windows ã—ã‹ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã›ã‚“ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pHFh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe_8bit1 = pipeline(model=\"facebook/opt-1.3b\", device_map=\"auto\", model_kwargs={\"load_in_8bit\": True})\n",
    "# pipe_8bit1(\"This is a cool example!\", do_sample=True, top_p=0.95)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
