{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "Hbol",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "# Pipelines for inference\n",
    "\n",
    "本チュートリアルでは、`pipeline()` を用いて、訓練済みモデルによって様々な推論タスクを実行する手法を学びます。\n",
    "ここで紹介するモデルのうちいくつかは非常に多くのパラメータをもつため、ロードのために多くのメモリやストレージを必要とします。\n",
    "ローカルで実行する際は注意してください。\n",
    "\n",
    "本チュートリアルは、[Hugging Face Transformers チュートリアル](https://huggingface.co/docs/transformers/v4.57.1/ja/pipeline_tutorial) を元に、一部加筆・修正して作成しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MJUe",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Dependencies\n",
    "\n",
    "このチュートリアルコードをすべて実行するためには、明示的に `import` するライブラリの他に、以下のソフトウェアが必要です。\n",
    "\n",
    "- [`ffmpeg`](https://www.ffmpeg.org/): 動画処理\n",
    "- [`tesseract`](https://github.com/tesseract-ocr/tesseract) (および、その Python ラッパー: `pytesseract`): 画像処理\n",
    "- `accelerate` ライブラリ: モデルの自動配置\n",
    "- `bitsandbytes` ライブラリ: モデルの量子化\n",
    "    - linux, windows のみサポート\n",
    "- `pillow` ライブラリ: 画像処理\n",
    "- `torchcodec` ライブラリ: 動画処理\n",
    "\n",
    "もし自分の環境にインストールされていない場合には、事前にインストールしておいてください。\\\n",
    "なお、`ffmpeg` と `tesseract` に関しては、macOSであれば [`Homebrew`](https://formulae.brew.sh) から簡単にインストールできるようです (動作未確認) 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vblA",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell if you are working in google colab\n",
    "\n",
    "%pip install accelerate bitsandbytes datasets transformers torch torchcodec pillow pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bkHC",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "from transformers.pipelines.pt_utils import KeyDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lEQa",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Pipeline usage\n",
    "\n",
    "`pipeline(task=\"task\")` により、推論タスク `\"task\"` を行うためのデフォルトのモデルが提供されます。\n",
    "提供される構造体は、入力に対して事前処理・推論・事後処理をワンライナーで実行します。\n",
    "\n",
    "<audio src=\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\" controls></audio>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PKri",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default model: \"facebook/wav2vec2-base-960h\" (94.4M params)\n",
    "# ref: (https://huggingface.co/facebook/wav2vec2-base-960h)\n",
    "\n",
    "pipe_asr1 = pipeline(task=\"automatic-speech-recognition\")\n",
    "pipe_asr1(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Xref",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "具体的な推論モデルを指定するには、`pipeline(model=\"model\")` とします。\n",
    "モデルの一覧は [`Hub`](https://huggingface.co/models) から確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SFPL",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare generator with model name\n",
    "# superior model: \"openai/whisper-large\" (1.54B params)\n",
    "# this may be too heavy for cpus ...\n",
    "\n",
    "pipe_asr2 = pipeline(model=\"openai/whisper-large\")\n",
    "pipe_asr2(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BYtC",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "複数の入力を `list` で受け取ることもできます。\n",
    "\n",
    "<audio src=\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\" controls></audio>\n",
    "\n",
    "<audio src=\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/1.flac\" controls></audio>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RGSE",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_asr1([\n",
    "    \"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\",\n",
    "    \"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/1.flac\",\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Kclp",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Parameter\n",
    "\n",
    "`pipeline()` はタスク固有・非固有の多くのパラメータをサポートしています。\n",
    "一般的には、このパラメータはどこでも指定できます。\n",
    "\n",
    "```python\n",
    "pipe = pipeline(..., my_parameter=1)\n",
    "out = pipe(...)                  # `my_parameter=1` is used here\n",
    "out = pipe(..., my_parameter=2)  # `my_parameter=2` is used here\n",
    "out = pipe(...)                  # `my_parameter=1` is used here\n",
    "```\n",
    "\n",
    "以下で、特によく用いられるパラメータを紹介します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emfo",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "### Device\n",
    "\n",
    "`device=n` を指定すると、モデルが指定したデバイスのメモリに配置されます。\n",
    "具体的な use case は以下の通りです。\n",
    "\n",
    "- `device=-1`: CPU\n",
    "- `device=n` (non-negative integer): on GPU with id `n`\n",
    "    - id はマシンを構成する各 GPU に自動的に割り振られています\n",
    "    - NVIDIA GPU であれば `torch.cuda.get_device_name(n)` で id `n` に対応する GPU デバイス名が取得できます\n",
    "\n",
    "なお、特に `device` の値を指定しなくても、GPU を使用するように自動的にデバイスが決定されるようです。\n",
    "筆者の環境 (M4 MacBook Air) では、Apple GPU (mps) が自動的に選択されました。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Hstk",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "### Batch Size\n",
    "\n",
    "`batch_size=n` を指定することで、バッチサイズ `n` で推論することができます。\n",
    "ただし、バッチ処理によって実行速度の向上が必ずしも期待できるわけではなく、いくつかのケースではかなり遅くなることが確認されているようです。\n",
    "なお、バッチ処理を行ったとしても、得られる結果はバッチ処理を行わない場合と一致します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nWHF",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "### Task specific parameters\n",
    "\n",
    "すべてのタスクにおいて、タスク固有のパラメータが提供されています。\n",
    "例えば、`transformers.AutomaticSpeechRecognitionPipeline.call()` メソッドには、適当な単位で推論結果を区切ってタイムスタンプと同時に出力する `return_timestamps` パラメータがあります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iLit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: \"facebook/wav2vec2-large-960h-lv60-self\" (317M params)\n",
    "# ref: https://huggingface.co/facebook/wav2vec2-large-960h-lv60-self\n",
    "\n",
    "pipe_asr3 = pipeline(model=\"facebook/wav2vec2-large-960h-lv60-self\", return_timestamps=\"word\")\n",
    "pipe_asr3(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZHCJ",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Using pipeline in a dataset\n",
    "\n",
    "`pipeline()` は大規模なデータセット上で推論を実行することもできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ROlb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: \"openai-community/gpt2\" (137M params)\n",
    "# ref: https://huggingface.co/openai-community/gpt2\n",
    "\n",
    "def data():\n",
    "    for i in range(10):\n",
    "        yield f\"My example {i}\"\n",
    "\n",
    "pipe_tg1 = pipeline(model=\"openai-community/gpt2\", device=0)\n",
    "generated_characters = 0\n",
    "for out_tg1 in pipe_tg1(data()):\n",
    "    generated_characters += len(out_tg1[0][\"generated_text\"])\n",
    "print(generated_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qnkX",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "`🤗 Datasets` からデータセットをロードして繰り返し反復させることもできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TqIu",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_asr4 = pipeline(model=\"hf-internal-testing/tiny-random-wav2vec2\", device=0)\n",
    "dataset_asr1 = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation[:10]\")\n",
    "\n",
    "for out_asr1 in pipe_asr4(KeyDataset(dataset_asr1, \"audio\")):\n",
    "    print(out_asr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Vxnm",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Using pipelines for a webserver\n",
    "\n",
    "このセクションは飛ばします。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DnEU",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Vision pipeline\n",
    "\n",
    "画像処理タスクでの使用例は以下の通りです。\n",
    "ここでは、写真に写っているオブジェクトを分類する推論タスクを実行しています。\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\" width=\"30%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ulZA",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: \"google/vit-base-patch16-224\" (86.6M params)\n",
    "# ref: https://huggingface.co/google/vit-base-patch16-224\n",
    "\n",
    "pipe_vc1 = pipeline(model=\"google/vit-base-patch16-224\")\n",
    "preds_vc1 = pipe_vc1(\n",
    "    inputs=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\",\n",
    ")\n",
    "preds_vc1 = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds_vc1]\n",
    "preds_vc1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfG",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Text pipeline\n",
    "\n",
    "テキスト処理タスクでの使用例は以下の通りです。\n",
    "ここでは、テキストのコンテンツの性格を分類するタスクを実行しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Pvdt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: \"facebook/bart-large-mnli\" (407M params)\n",
    "# ref: https://huggingface.co/facebook/bart-large-mnli\n",
    "\n",
    "pipe_tc1 = pipeline(model=\"facebook/bart-large-mnli\")\n",
    "pipe_tc1(\n",
    "    \"I have a problem with my iphone that needs to be resolved asap!!\",\n",
    "    candidate_labels=[\"urgent\", \"not urgent\", \"phone\", \"tablet\", \"computer\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZBYS",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Multimodal pipeline\n",
    "\n",
    "`pipeline()` は、複数のモダリティをサポートしています。\n",
    "ここでは、テキスト処理と画像処理を組み合わせて、画像からインボイス番号を推論させています。\n",
    "\n",
    "<img src=\"https://huggingface.co/spaces/impira/docquery/resolve/2359223c1837a7587402bda0f2643382a6eefeab/invoice.png\" width=\"30%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aLJB",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: \"impira/layoutlm-document-qa\" (128M params)\n",
    "# ref: https://huggingface.co/impira/layoutlm-document-qa\n",
    "\n",
    "pipe_dqa = pipeline(model=\"impira/layoutlm-document-qa\")\n",
    "out_dqa1 = pipe_dqa(\n",
    "    image=\"https://huggingface.co/spaces/impira/docquery/resolve/2359223c1837a7587402bda0f2643382a6eefeab/invoice.png\",\n",
    "    question=\"What is the invoice number?\",\n",
    ")\n",
    "out_dqa1[0][\"score\"] = round(out_dqa1[0][\"score\"], 3)\n",
    "out_dqa1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nHfw",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Using pipeline on large models with 🤗 accelarate\n",
    "\n",
    "`device_map=\"auto\"` を指定して、モデルを利用可能なデバイス上で適切に分配してロードします。\n",
    "これにより、単一のデバイスではメモリに乗り切らない大規模なモデルを利用することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xXTn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: \"facebook/opt-1.3b\" (1.3B params, heavy)\n",
    "# ref: https://huggingface.co/facebook/opt-1.3b\n",
    "\n",
    "# pipe_acc1 = pipeline(model=\"facebook/opt-1.3b\", dtype=torch.bfloat16, device_map=\"auto\")\n",
    "# pipe_acc1(\"これは素晴らしい例です！\", do_sample=True, top_p=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AjVT",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "さらに、`bitsandbytes` ライブラリをインストールの上、`load_in_8bit=True` を指定すれば、モデルを 8 bit で量子化して読み込むことができます。\n",
    "ただし、`bitsandbytes` は現状 linux と windows しかサポートしていません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pHFh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe_8bit1 = pipeline(model=\"facebook/opt-1.3b\", device_map=\"auto\", model_kwargs={\"load_in_8bit\": True})\n",
    "# pipe_8bit1(\"This is a cool example!\", do_sample=True, top_p=0.95)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
